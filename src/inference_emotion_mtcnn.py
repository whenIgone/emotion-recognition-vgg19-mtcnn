# -*- coding: utf-8 -*-
"""emotion_recognition_inference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QrTEg54bFcJL0Qf3O-yrCAf1LboG-hww

# üé≠ Reconhecimento de Emo√ß√µes Faciais - Infer√™ncia

**Modelo:** VGG19 treinado no CK+ Dataset

**Emo√ß√µes:** anger, disgust, fear, happiness, sadness

## üì¶ 1. Imports e Configura√ß√µes
"""

from tensorflow.keras.models import load_model
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import cv2
import os
from glob import glob

print("‚úì Imports carregados com sucesso!")

"""## üß† 2. Carregar Modelo Treinado"""

# Diret√≥rio do modelo salvo
SAVE_DIR = r'C:\Users\lukai\Documents\Programa√ß√£o\CNN\resultados'
model = load_model(os.path.join(SAVE_DIR, 'best_model_phase2.keras'))

# Configura√ß√µes
EMOTIONS_TO_USE = ['anger', 'disgust', 'fear', 'happiness', 'sadness']
IMG_SIZE = (224, 224)

print("‚úì Modelo carregado com sucesso!")
print(f"‚úì Emo√ß√µes: {EMOTIONS_TO_USE}")
print(f"‚úì Tamanho de entrada: {IMG_SIZE}")

"""## üîç 3. Fun√ß√£o de Predi√ß√£o com Detec√ß√£o de Rosto"""

from mtcnn import MTCNN
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import cv2

# Criar detector MTCNN (uma vez s√≥)
detector = MTCNN()

def predict_emotion(image_path, model, emotions):
    """Prediz emo√ß√£o com detec√ß√£o MTCNN"""

    try:
        # Carregar imagem
        pil_img = Image.open(image_path).convert('RGB')
        img_rgb = np.array(pil_img)
        print(f"‚úì Imagem carregada: {img_rgb.shape}")

        # Detectar rostos com MTCNN
        faces = detector.detect_faces(img_rgb)

        detected = False
        if len(faces) > 0:
            # Pegar maior rosto
            face = max(faces, key=lambda f: f['box'][2] * f['box'][3])
            x, y, w, h = face['box']

            # Margem
            margin = int(0.15 * max(w, h))
            x = max(0, x - margin)
            y = max(0, y - margin)
            w = min(img_rgb.shape[1] - x, w + 2*margin)
            h = min(img_rgb.shape[0] - y, h + 2*margin)

            face_img = img_rgb[y:y+h, x:x+w]
            detected = True
            print(f"‚úì Rosto detectado: {w}x{h} px (confian√ßa: {face['confidence']:.2f})")
        else:
            print("‚ö†Ô∏è Nenhum rosto detectado, usando imagem completa")
            face_img = img_rgb

        # Preprocessar
        face_pil = Image.fromarray(face_img).resize(IMG_SIZE)
        img_array = np.array(face_pil) / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        # Predi√ß√£o
        predictions = model.predict(img_array, verbose=0)
        pred_idx = np.argmax(predictions[0])
        confidence = predictions[0][pred_idx] * 100

        print(f"\n{'='*60}")
        print(f"Predicted: {emotions[pred_idx].upper()}")
        print(f"Confidence: {confidence:.2f}%")
        print(f"{'='*60}\n")

        # Visualiza√ß√£o
        if detected:
            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))

            rect_img = img_rgb.copy()
            cv2.rectangle(rect_img, (x, y), (x+w, y+h), (0, 255, 0), 3)
            ax1.imshow(rect_img)
            ax1.axis('off')
            ax1.set_title('Original (Rosto Detectado)', fontsize=12)

            ax2.imshow(face_pil)
            ax2.axis('off')
            ax2.set_title(f'{emotions[pred_idx].upper()} ({confidence:.1f}%)',
                          fontsize=14, fontweight='bold')

            colors = ['#ef553b', '#cccc00', '#63be7b', '#00bfc4', '#ab63fa']
            ax3.barh(emotions, predictions[0], color=colors)
            ax3.set_xlabel('Probability', fontsize=12)
            ax3.set_title('Emotion Probabilities', fontsize=14)
            ax3.set_xlim(0, 1)
        else:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

            ax1.imshow(face_pil)
            ax1.axis('off')
            ax1.set_title(f'{emotions[pred_idx].upper()} ({confidence:.1f}%)',
                          fontsize=14, fontweight='bold')

            colors = ['#ef553b', '#cccc00', '#63be7b', '#00bfc4', '#ab63fa']
            ax2.barh(emotions, predictions[0], color=colors)
            ax2.set_xlabel('Probability', fontsize=12)
            ax2.set_title('Emotion Probabilities', fontsize=14)
            ax2.set_xlim(0, 1)

        plt.tight_layout()
        plt.show()

    except Exception as e:
        print(f"‚ùå Erro: {str(e)}")

print("‚úì Fun√ß√£o predict_emotion com MTCNN carregada!")
print("‚úì Detec√ß√£o de rosto: Habilitada (MTCNN)")

"""## üìÅ 4. Teste com M√∫ltiplas Imagens

Execute a c√©lula abaixo para fazer upload de uma ou mais imagens e ver a predi√ß√£o do modelo.

**Instru√ß√µes:**
1. Coloque suas imagens na pasta `test_img`
2. Execute a c√©lula
3. Veja os resultados!
"""

# Diret√≥rio com imagens para testar
directory = r'C:\Users\lukai\Documents\Programa√ß√£o\CNN\test_img'

# Buscar todas as imagens
image_paths = glob(os.path.join(directory, '*.jpg')) + \
              glob(os.path.join(directory, '*.jpeg')) + \
              glob(os.path.join(directory, '*.png'))

if len(image_paths) == 0:
    print(f"‚ùå Nenhuma imagem encontrada em: {directory}")
else:
    print(f"‚úì {len(image_paths)} imagem(s) encontrada(s)\n")

    for filepath in image_paths:
        filename = os.path.basename(filepath)
        print(f"\n{'='*60}")
        print(f"Processando: {filename}")
        print(f"{'='*60}")

        try:
            predict_emotion(filepath, model, EMOTIONS_TO_USE)
        except Exception as e:
            print(f"‚ùå Erro: {str(e)}")

"""## 5. Teste com Imagem √önica

Se quiser testar apenas uma imagem espec√≠fica, use a c√©lula abaixo:
"""

# Caminho da imagem √∫nica para testar
single_image_path = r'C:\Users\lukai\Documents\Programa√ß√£o\CNN\test_img\20251026_172545.jpg'

# Predizer
predict_emotion(single_image_path, model, EMOTIONS_TO_USE)